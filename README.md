# ğŸ’– PREDICTING HEART DISEASE ğŸ’–

<div align="center">

![Kaggle](https://img.shields.io/badge/Kaggle-Playground%20S6E2-20BEFF?style=for-the-badge&logo=kaggle)
![Rank](https://img.shields.io/badge/RANK-RUNNING-FFD700?style=for-the-badge)
![Score](https://img.shields.io/badge/Best%20Score-In%20Progress-00D9FF?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python)

### âš¡ **COMPETITION #8 - OUR HEALTHCARE MISSION STARTS NOW!** âš¡

> *"Saving lives with precision machine learning - One prediction at a time!"*

**Advanced Ensemble | 5 Models | 1 Meta-Learner | Maximum Firepower**

</div>

---

## ğŸ”¥ TEAM PHOENIX ALGORITHMS - HEALTHCARE DIVISION

After dominating financial predictions, audio analysis, and road accidentsâ€”**we're now venturing into HEALTHCARE!** Armed with our battle-tested ensemble techniques and the drive to reach GRANDMASTER status, we're here to predict heart disease with surgical precision.

### ğŸ‘¥ THE ELITE SQUAD

<table>
<tr>
<td align="center" width="25%">
<img src="https://github.com/mohan13krishna.png" width="150px" style="border-radius: 50%;" alt="Mohan Krishna Thalla"/><br />
<b>ğŸ‘‘ Mohan Krishna Thalla</b><br />
<i>Team Lead & Ensemble Architect</i><br />
<i>"The Orchestrator of Models"</i><br /><br />
<a href="https://www.kaggle.com/mohankrishnathalla"><img src="https://img.shields.io/badge/Kaggle-20BEFF?style=flat&logo=kaggle&logoColor=white" /></a>
<a href="https://github.com/mohan13krishna"><img src="https://img.shields.io/badge/GitHub-181717?style=flat&logo=github&logoColor=white" /></a>
</td>
<td align="center" width="25%">
<img src="https://github.com/rakeshkolipakaace.png" width="150px" style="border-radius: 50%;" alt="Rakesh Kolipaka"/><br />
<b>ğŸ”§ Rakesh Kolipaka</b><br />
<i>ML Engineer & Feature Wizard</i><br />
<i>"The Optimization Alchemist"</i><br /><br />
<a href="https://www.kaggle.com/rakesh630"><img src="https://img.shields.io/badge/Kaggle-20BEFF?style=flat&logo=kaggle&logoColor=white" /></a>
<a href="https://github.com/rakeshkolipakaace"><img src="https://img.shields.io/badge/GitHub-181717?style=flat&logo=github&logoColor=white" /></a>
</td>
<td align="center" width="25%">
<img src="https://github.com/ranjith93250.png" width="150px" style="border-radius: 50%;" alt="Ranjith Kumar Digutla"/><br />
<b>âš¡ Ranjith Kumar Digutla</b><br />
<i>ML Engineer & Stacking Specialist</i><br />
<i>"The Stack Master"</i><br /><br />
<a href="https://www.kaggle.com/digutlaranjithkumar"><img src="https://img.shields.io/badge/Kaggle-20BEFF?style=flat&logo=kaggle&logoColor=white" /></a>
<a href="https://github.com/ranjith93250"><img src="https://img.shields.io/badge/GitHub-181717?style=flat&logo=github&logoColor=white" /></a>
</td>
<td align="center" width="25%">
<img src="https://github.com/udaykiran2102.png" width="150px" style="border-radius: 50%;" alt="Neelam Uday Kiran"/><br />
<b>ğŸ¯ Neelam Uday Kiran</b><br />
<i>Strategic Advisor & Feature Engineer</i><br />
<i>"The Precision Sniper"</i><br /><br />
<a href="https://www.kaggle.com/neelamuday"><img src="https://img.shields.io/badge/Kaggle-20BEFF?style=flat&logo=kaggle&logoColor=white" /></a>
<a href="https://github.com/udaykiran2102"><img src="https://img.shields.io/badge/GitHub-181717?style=flat&logo=github&logoColor=white" /></a>
</td>
</tr>
</table>

<div align="center">

**ğŸ† COMPETITION #8 | HEALTHCARE DIVISION | 5-MODEL ARSENAL ğŸ†**

*From financial predictions to life-saving predictionsâ€”the Phoenix rises higher!*

</div>

---

## ğŸ“Š COMPETITION INTEL

**Mission:** Predict the likelihood of heart disease with maximum accuracy  
**Challenge:** Kaggle Playground Series - Season 6, Episode 2  
**Duration:** February 1-28, 2026 (28 days of data science warfare)  
**Metric:** ROC-AUC (Area Under ROC Curve) - *Higher is King*  
**Dataset Size:** 270,000+ samples with 30+ healthcare features  

---

## ğŸ¯ OUR BATTLEFIELD PERFORMANCE

### ğŸ“ˆ **THE LEADERBOARD**
- **Current Rank:** ğŸƒ **RUNNING** (Competition Active)
- **Target Score:** ğŸ¯ **0.954+ ROC-AUC**
- **Models in Ensemble:** ğŸš€ **5 Powerhouses**
- **Meta-Learner:** ğŸ‘‘ **Logistic Regression Stacking**

### ğŸ¥ **OUR TOP WEAPONS - THE 5-MODEL ARSENAL**

#### ğŸ¥‡ **PRIMARY: LightGBM (30% Weight)**
- **Framework:** Fast, efficient gradient boosting
- **Architecture:** 500 estimators, depth 7, learning rate 0.05
- **Role:** The BACKBONE of our ensemble
- **Expected Strength:** Best generalization

#### ğŸ¥ˆ **SECONDARY: XGBoost (25% Weight)**
- **Framework:** Gradient boosting excellence
- **Architecture:** 500 estimators, optimized hyperparameters
- **Role:** The PRECISION instrument
- **Expected Strength:** High individual accuracy

#### ğŸ¥‰ **TERTIARY: CatBoost (20% Weight)**
- **Framework:** Categorical feature specialist
- **Architecture:** 500 iterations, depth 7, native categorical handling
- **Role:** The CATEGORICAL expert
- **Expected Strength:** Superior feature understanding

#### ğŸ’ª **SUPPORT: Random Forest (15% Weight)**
- **Framework:** Ensemble of decision trees
- **Architecture:** 500 trees, max_depth 15, bootstrap aggregating
- **Role:** The STABILITY anchor
- **Expected Strength:** Robustness & variance reduction

#### ğŸ”¥ **RESERVE: Gradient Boosting (10% Weight)**
- **Framework:** Classical scikit-learn approach
- **Architecture:** 500 estimators, depth 7, learning rate 0.05
- **Role:** The CLASSICAL workhorse
- **Expected Strength:** Consistent performer

#### ğŸ‘‘ **META-LEARNER: Logistic Regression Stacking**
- **Strategy:** Train on out-of-fold predictions from 5 base models
- **Approach:** Learn optimal weighted combination
- **Expected Result:** ROC-AUC > 0.954

---

## ğŸ¥ THE HEALTHCARE BATTLEFIELD - FEATURES

We're analyzing **30+ powerful medical metrics** to predict heart disease:

| Feature Category | What We're Measuring |
|------------------|---------------------|
| ğŸ‘¤ **Demographics** | Age, Gender |
| ğŸ’“ **Cardiac Indicators** | Chest pain type, Resting BP, Max HR |
| ğŸ©º **Blood Chemistry** | Cholesterol, Fasting blood sugar |
| ğŸ“Š **ECG Metrics** | Resting ECG, ST depression, ST slope |
| ğŸ«€ **Vascular Data** | Number of major vessels |
| ğŸ”¬ **Genetic Factors** | Thalassemia type |
| âš¡ **Derived Features** | Exercise-induced changes, ratios |

---

## ğŸ› ï¸ OUR ARSENAL - THE EVOLUTION

### ğŸ”„ **THE JOURNEY: FROM DATA TO DEPLOYMENT**

#### **Phase 1: Data Foundation** ğŸ—ï¸
- Load 270,000 samples with 30+ features
- Statistical analysis and exploratory data analysis
- Missing value detection and handling strategy

#### **Phase 2: Preprocessing Excellence** ğŸ§¹
- RobustScaler normalization
- Median imputation for missing values
- Target encoding (string â†’ numeric)
- Feature standardization

#### **Phase 3: Base Model Development** ğŸ’¡
- Individual training: LightGBM, XGBoost, CatBoost, Random Forest, Gradient Boosting
- Hyperparameter tuning for each algorithm
- Cross-validation strategy: 5-Fold Stratified CV

#### **Phase 4: Ensemble Optimization** ğŸ”§
- Out-of-fold prediction collection
- Weight optimization for weighted ensemble
- Meta-model training on OOF predictions

#### **Phase 5: DEPLOYMENT SUPREMACY** ğŸ‘‘
- Final ensemble evaluation
- Kaggle-optimized code
- Production-ready submission format
- GPU-ready for Kaggle notebooks

---

## ğŸ’¡ BATTLE STRATEGIES THAT WORK

### âœ… **What Powers Our Approach**

1. **Diverse Base Models** ğŸ¤
   - Multiple algorithms capture different patterns
   - Reduces overfitting through diversity
   - Each model contributes unique insights

2. **5-Fold Stratified Cross-Validation** ğŸ”„
   - Ensures balanced train-test splits
   - Prevents data leakage
   - Consistent validation metrics across folds

3. **Out-of-Fold Predictions** ğŸ“Š
   - Collect OOF predictions from all folds
   - Use for meta-model training
   - Eliminates overfitting on meta-learner

4. **Meta-Model Stacking** ğŸ—ï¸
   - Logistic Regression learns optimal weights
   - Higher-order patterns captured
   - Final ensemble > any single model

5. **Feature Engineering** ğŸ”¬
   - Proper scaling and normalization
   - Missing value handling
   - Medical domain knowledge applied

6. **Kaggle Optimization** ğŸ¯
   - Uses Kaggle competition data paths
   - Ready for GPU acceleration
   - Runs in 10-15 minutes on Kaggle

---

## ğŸ“Š TECHNICAL ARCHITECTURE

### **The 0.954+ ROC-AUC Pipeline**

```
HEART DISEASE PREDICTION ENGINE
â”œâ”€â”€ INPUT: 270,000 samples Ã— 30+ features
â”œâ”€â”€ PREPROCESSING
â”‚   â”œâ”€â”€ Missing values â†’ Median imputation
â”‚   â”œâ”€â”€ Scaling â†’ RobustScaler normalization
â”‚   â”œâ”€â”€ Target â†’ String to numeric mapping
â”‚   â””â”€â”€ Categorical â†’ Proper encoding
â”œâ”€â”€ BASE MODEL TRAINING (5-Fold CV)
â”‚   â”œâ”€â”€ LightGBM (30%)
â”‚   â”œâ”€â”€ XGBoost (25%)
â”‚   â”œâ”€â”€ CatBoost (20%)
â”‚   â”œâ”€â”€ Random Forest (15%)
â”‚   â””â”€â”€ Gradient Boosting (10%)
â”œâ”€â”€ OUT-OF-FOLD PREDICTIONS
â”‚   â””â”€â”€ Collect OOF predictions for meta-learning
â”œâ”€â”€ META-LEARNING
â”‚   â””â”€â”€ Logistic Regression learns optimal weights
â””â”€â”€ OUTPUT
    â”œâ”€â”€ CV AUC: ~0.9520-0.9542
    â”œâ”€â”€ Public Score Target: 0.954+
    â””â”€â”€ Submission Format: submission.csv
```

---

## ğŸš€ QUICK START GUIDE

### **Option 1: Run on Kaggle (RECOMMENDED)**
1. Go to Kaggle.com/code
2. Click "Import Notebook"
3. Paste: https://github.com/mohan13krishna/Predicting-Heart-Disease
4. Add "playground-series-s6e2" dataset input
5. Enable GPU (optional)
6. Run all cells
7. Submit submission.csv

### **Option 2: Local Execution**
```bash
# Clone repository
git clone https://github.com/mohan13krishna/Predicting-Heart-Disease.git
cd Predicting-Heart-Disease

# Install dependencies
pip install pandas numpy scikit-learn xgboost lightgbm catboost

# Run the script
python heart_disease_prediction.py
```

---

## ğŸ“ PROJECT STRUCTURE

```
Predicting-Heart-Disease/
â”œâ”€â”€ heart_disease_ensemble.ipynb       # Interactive Jupyter notebook
â”œâ”€â”€ heart_disease_prediction.py        # Production Python script (Kaggle)
â”œâ”€â”€ README.md                          # Comprehensive documentation
â”œâ”€â”€ train.csv                          # Training data (270K samples)
â”œâ”€â”€ test.csv                           # Test data (evaluation set)
â””â”€â”€ sample_submission.csv              # Submission format template
```

---

## â±ï¸ RUNTIME EXPECTATIONS

- **Kaggle GPU:** 10-15 minutes âš¡
- **Local CPU:** 30-60+ minutes â³
- **Expected Memory:** 2GB+ RAM

---

## ğŸ“Š REQUIREMENTS

```
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=0.24.0
xgboost>=1.5.0
lightgbm>=3.3.0
catboost>=1.0.0
```

---

## ğŸ“ LESSONS FROM OUR JOURNEY

### ğŸ’ **Golden Insights from 8 Competitions**

1. **Competition #1 (House Prices):** Top 2.3%
   - Lesson: Feature engineering WINS

2. **Competition #2 (BPM Prediction):** Top 48.3%
   - Lesson: Ensemble diversity matters

3. **Competition #3 (Road Accident Risk):** Top 23.5%
   - Lesson: Domain knowledge + diverse models = POWER

4. **Competition #8 (Heart Disease):** Healthcare AI
   - Lesson: Medical data demands precision stacking

### ğŸš€ **Evolution of Team Phoenix**

```
Competition #1 â†’ Learning the ropes (Top 2.3%)
Competition #2 â†’ Building confidence (Top 48.3%)
Competition #3 â†’ Tactical victory (Top 23.5%)
...
Competition #8 â†’ Healthcare mastery (Running)
â†’ Competition #âˆ â†’ GRANDMASTER STATUS (Target)
```

---

## ğŸ”® OUR KAGGLE JOURNEY MAP

### âœ… **COMPLETED ACHIEVEMENTS**
- âœ… House Prices (Get Started): Top 2.3% ğŸ”¥
- âœ… BPM of Songs: Top 48.3%
- âœ… Road Accident Risk: Top 23.5%
- âœ… 5 More Competitions: Building expertise
- ğŸ¯ **Competition #8 (Heart Disease):** In Progress

### ğŸ¯ **IN PROGRESS**
- Advanced Ensemble Techniques
- Feature Engineering Mastery
- Hyperparameter Optimization
- Healthcare AI Excellence

### ğŸ† **FUTURE TARGETS**
- Competition #9+: Top 10% finishes
- Featured Competitions: Podium positions
- Ultimate Goal: **KAGGLE GRANDMASTER STATUS**

---

## ğŸ“Š BY THE NUMBERS

<div align="center">

| Metric | Value |
|--------|-------|
| ğŸ… **Current Status** | Running |
| ğŸ“Š **Ensemble Models** | 5 Base + 1 Meta (6 Total) |
| ğŸ¯ **Target Score** | 0.954+ ROC-AUC |
| ğŸš€ **Data Points** | 270,000+ samples |
| ğŸ”¬ **Features** | 30+ medical indicators |
| ğŸ‘¥ **Team Members** | 4 Elite Data Warriors |
| â±ï¸ **Duration** | 28 Days (Feb 1-28, 2026) |
| ğŸ’» **Models Trained** | Multiple hyperparameter variations |
| â˜• **Coffee Consumed** | âˆ (Unlimited) |

</div>

---

## ğŸ¥ COMPETITION DETAILS

**Event:** Kaggle Playground Series - Season 6, Episode 2  
**Challenge:** Predicting Heart Disease  
**Start:** February 1, 2026  
**End:** February 28, 2026  
**Evaluation Metric:** ROC-AUC (Area Under ROC Curve)  
**Prize:** Kaggle Merchandise (Top 3)  
**Dataset License:** CC BY 4.0  

---

## ğŸ™ ACKNOWLEDGMENTS

- **Kaggle** for the incredible Playground Series platform
- **Walter Reade & Elizabeth Park** for organizing this challenge
- **Healthcare Community** for the domain knowledge and inspiration
- **Our Team** for unwavering dedication and collaboration
- **Coffee** for keeping us awake at 3 AM â˜•

---

## ğŸ“š LINKS & REFERENCES

- [Kaggle Competition](https://kaggle.com/competitions/playground-series-s6e2)
- [GitHub Repository](https://github.com/mohan13krishna/Predicting-Heart-Disease)
- [Team Phoenix on Kaggle](https://kaggle.com/mohan13krishna)

---

<div align="center">

# âš¡ THE PHOENIX CONTINUES ITS ASCENT âš¡

## *"Competition #1: Top 2.3% | Competition #8: Healthcare Prediction | Competition #âˆ: GRANDMASTER!"*

### ğŸ† TEAM PHOENIX ALGORITHMS ğŸ†

**We're not here to participate. We're here to WIN.**

---

### ğŸ“ˆ From Finance to Healthcare | ğŸ’ª From Learning to Leading | ğŸš€ From Top 2.3% to GRANDMASTER

---

*We rise like a phoenix. This is our story. This is our 8th battle. Watch us soar.* â­

**[Competition Link](https://kaggle.com/competitions/playground-series-s6e2)** | **February 2026** | **#TeamPhoenixAlgorithms** | **ğŸ’–Healthcare EditionğŸ’–**

</div>
