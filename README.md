ğŸ’– PREDICTING HEART DISEASE - ENSEMBLE LEARNING MASTERCLASS ğŸ’–
Kaggle Rank Score Python

âš¡ OUR 8TH COMPETITION - HEALTHCARE PREDICTION WITH MAXIMUM FIREPOWER âš¡
"Saving lives with precision machine learning - One prediction at a time!"

5-Model Ensemble | Meta-Model Stacking | Production-Ready Code

ğŸ”¥ TEAM PHOENIX ALGORITHMS - HEALTHCARE DIVISION
Our 8th Kaggle competition takes us from financial predictions, to road accidents, to audio analysis...
Now we're stepping into HEALTHCARE with the same precision and determination that got us TOP 2.3%!

ğŸ‘¥ THE ELITE SQUAD
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           THE TEAM PHOENIX LINEUP                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ‘‘ Mohan Krishna Thalla                             â”‚
â”‚     Team Lead & Ensemble Architect                   â”‚
â”‚     "The Orchestrator of Models"                     â”‚
â”‚                                                      â”‚
â”‚  ğŸ”§ Rakesh Kolipaka                                  â”‚
â”‚     ML Engineer & Feature Wizard                     â”‚
â”‚     "The Optimization Alchemist"                     â”‚
â”‚                                                      â”‚
â”‚  âš¡ Ranjith Kumar Digutla                            â”‚
â”‚     ML Engineer & Stacking Specialist                â”‚
â”‚     "The Stack Master"                               â”‚
â”‚                                                      â”‚
â”‚  ğŸ¯ Neelam Uday Kiran                                â”‚
â”‚     Strategic Advisor & Feature Engineer             â”‚
â”‚     "The Precision Sniper"                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† COMPETITION #8 | PREDICTING HEART DISEASE | KAGGLE PLAYGROUND S6E2 ğŸ†

Heart Disease Prediction with Ensemble Excellence

ğŸ“Š MISSION BRIEFING
Objective: Predict likelihood of heart disease with surgical precision
Competition: Kaggle Playground Series - Season 6, Episode 2
Status: Advanced Ensemble Research & Development
Metric: ROC-AUC (Area Under ROC Curve) - Higher is Better
Target Score: ROC-AUC > 0.954
Dataset: 270,000+ samples with 30+ features

ğŸ¯ THE HEALTHCARE ARSENAL - 5-MODEL DEATH STAR
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     THE ENSEMBLE THAT PREDICTS HEART DISEASE          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  ğŸ¯ LightGBM (30% Weight)                              â”‚
â”‚     â”œâ”€ Fast gradient boosting framework                â”‚
â”‚     â”œâ”€ 500 estimators with depth 7                     â”‚
â”‚     â”œâ”€ Learning rate: 0.05                             â”‚
â”‚     â””â”€ The BACKBONE of our ensemble                    â”‚
â”‚                                                        â”‚
â”‚  ğŸ¯ XGBoost (25% Weight)                               â”‚
â”‚     â”œâ”€ Gradient boosting excellence                    â”‚
â”‚     â”œâ”€ Optimized hyperparameters                       â”‚
â”‚     â”œâ”€ Eval metric: logloss                            â”‚
â”‚     â””â”€ The PRECISION instrument                        â”‚
â”‚                                                        â”‚
â”‚  ğŸ¯ CatBoost (20% Weight)                              â”‚
â”‚     â”œâ”€ Categorical feature specialist                  â”‚
â”‚     â”œâ”€ 500 iterations with depth 7                     â”‚
â”‚     â”œâ”€ Native categorical handling                     â”‚
â”‚     â””â”€ The CATEGORICAL expert                          â”‚
â”‚                                                        â”‚
â”‚  ğŸ¯ Random Forest (15% Weight)                         â”‚
â”‚     â”œâ”€ Ensemble of decision trees                      â”‚
â”‚     â”œâ”€ 500 trees with max_depth 15                     â”‚
â”‚     â”œâ”€ Bootstrap aggregating power                     â”‚
â”‚     â””â”€ The STABILITY anchor                            â”‚
â”‚                                                        â”‚
â”‚  ğŸ¯ Gradient Boosting (10% Weight)                     â”‚
â”‚     â”œâ”€ Classical scikit-learn approach                 â”‚
â”‚     â”œâ”€ 500 estimators with depth 7                     â”‚
â”‚     â”œâ”€ Learning rate: 0.05                             â”‚
â”‚     â””â”€ The CLASSICAL workhorse                         â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â¬‡ï¸ META-MODEL STACKING â¬‡ï¸
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LOGISTIC REGRESSION META-LEARNER                     â”‚
â”‚                                                        â”‚
â”‚  The 5 models feed their OOF predictions into         â”‚
â”‚  a Logistic Regression meta-model that learns         â”‚
â”‚  the optimal combination of predictions!              â”‚
â”‚                                                        â”‚
â”‚  Result: ROC-AUC > 0.954 POTENTIAL ACHIEVED           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ›£ï¸ THE DATA LANDSCAPE - HEART DISEASE FEATURES
We analyze 30+ medical and health-related features:

ğŸ¥ Core Health Indicators
- Age: Patient age in years
- Sex: Gender
- Chest Pain Type: cp (1-4)
- Resting BP: resting blood pressure
- Cholesterol: serum cholesterol
- Fasting BS: fasting blood sugar
- Resting ECG: resting electrocardiogram
- Max HR: maximum heart rate achieved
- Oldpeak: ST depression induced by exercise
- ST Slope: slope of ST segment
- Num Vessels: number of major vessels (0-3)
- Thal: thalassemia type
- Plus many more derived features...

ğŸ”§ OUR ENGINEERING STRATEGY
- âœ… Robust Scaling (RobustScaler)
- âœ… Missing Value Handling (Median Imputation)
- âœ… Target Encoding (String to Numeric)
- âœ… Feature Normalization
- âœ… Class Balance Analysis

ğŸ› ï¸ THE ARSENAL EVOLUTION
ğŸ”„ OUR JOURNEY: FROM DATA TO DEPLOYMENT

Phase 1: Problem Understanding ğŸ—ï¸
Understanding heart disease prediction landscape
Analyzing 270,000 patient records
Learning from medical dataset patterns

Phase 2: Base Model Development ğŸ’¡
Individual model training & evaluation
XGBoost, LightGBM, CatBoost setup
Random Forest & Gradient Boosting configuration

Phase 3: Cross-Validation Excellence ğŸ”¬
5-Fold Stratified Cross-Validation
Out-of-fold prediction collection
Validation score tracking

Phase 4: Meta-Model Stacking ğŸ‘‘
Creating meta-features from base predictions
Training Logistic Regression meta-learner
Learning optimal model combination weights

Phase 5: DEPLOYMENT SUPREMACY ğŸš€
Kaggle-optimized code
Production-ready submission format
Clean, documented, reproducible pipeline

Result: Healthcare Prediction Excellence! ğŸ’–

ğŸ’¡ THE WINNING STRATEGIES
âœ… What Powers Our Approach

Diverse Base Models ğŸ¤
Multiple algorithms capture different patterns
Reduces overfitting through diversity
Each model contributes unique insights

5-Fold Stratified Cross-Validation ğŸ”„
Ensures robust evaluation
Prevents data leakage
Consistent validation metrics

Meta-Model Stacking ğŸ—ï¸
Logistic Regression learns optimal weights
Out-of-fold predictions prevent overfitting
Final ensemble > any single model

Feature Engineering ğŸ”¬
Proper scaling and normalization
Missing value handling
Medical domain knowledge applied

Kaggle Optimization ğŸ¯
Uses Kaggle competition data paths
Ready for GPU acceleration
Runs in 10-15 minutes on Kaggle

ğŸ“Š THE TECHNICAL ARCHITECTURE
ğŸ—ï¸ THE 0.954+ ROC-AUC MASTERPIECE
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        THE HEART DISEASE PREDICTION ENGINE         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                    â•‘
â•‘  ğŸ“¥ INPUT: 270,000 samples Ã— 30+ features         â•‘
â•‘        â¬‡ï¸                                          â•‘
â•‘  ğŸ§¹ PREPROCESSING                                  â•‘
â•‘     â”œâ”€ Missing values â†’ Median imputation          â•‘
â•‘     â”œâ”€ Scaling â†’ RobustScaler normalization        â•‘
â•‘     â”œâ”€ Target â†’ String to numeric mapping          â•‘
â•‘     â””â”€ Categorical â†’ Proper encoding               â•‘
â•‘        â¬‡ï¸                                          â•‘
â•‘  ğŸ­ BASE MODEL TRAINING (5-Fold CV)                â•‘
â•‘     â”œâ”€ ğŸ¯ LightGBM (30%)                          â•‘
â•‘     â”œâ”€ ğŸ¯ XGBoost (25%)                           â•‘
â•‘     â”œâ”€ ğŸ¯ CatBoost (20%)                          â•‘
â•‘     â”œâ”€ ğŸ¯ Random Forest (15%)                     â•‘
â•‘     â””â”€ ğŸ¯ Gradient Boosting (10%)                 â•‘
â•‘        â¬‡ï¸                                          â•‘
â•‘  ğŸ“Š OUT-OF-FOLD PREDICTIONS                        â•‘
â•‘     â””â”€ Collect OOF predictions for meta-learning   â•‘
â•‘        â¬‡ï¸                                          â•‘
â•‘  ğŸ—ï¸ META-LEARNING                                  â•‘
â•‘     â””â”€ Logistic Regression learns optimal weights  â•‘
â•‘        â¬‡ï¸                                          â•‘
â•‘  ğŸ“¤ OUTPUT                                          â•‘
â•‘     â”œâ”€ CV AUC: ~0.9520-0.9542                      â•‘
â•‘     â”œâ”€ Public Score: 0.954+ (Target)               â•‘
â•‘     â””â”€ Format: submission.csv (270K predictions)   â•‘
â•‘                                                    â•‘
â•‘  STATUS: ğŸ‘‘ PRODUCTION READY ğŸ‘‘                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ QUICK START GUIDE

### Option 1: Run on Kaggle (RECOMMENDED)
```
1. Go to Kaggle.com/code
2. Click "Import Notebook"
3. Paste: https://github.com/mohan13krishna/Predicting-Heart-Disease
4. Add "playground-series-s6e2" dataset input
5. Enable GPU (optional)
6. Run all cells
7. Submit submission.csv
```

### Option 2: Local Execution
```bash
# Clone repository
git clone https://github.com/mohan13krishna/Predicting-Heart-Disease.git
cd Predicting-Heart-Disease

# Install dependencies
pip install pandas numpy scikit-learn xgboost lightgbm catboost

# Run the script
python heart_disease_prediction.py
```

## ğŸ“ Project Structure
```
Predicting-Heart-Disease/
â”œâ”€â”€ heart_disease_ensemble.ipynb          # Notebook version
â”œâ”€â”€ heart_disease_prediction.py           # Python script (Kaggle)
â”œâ”€â”€ README.md                             # Documentation
â”œâ”€â”€ train.csv                             # Training data
â”œâ”€â”€ test.csv                              # Test data
â””â”€â”€ sample_submission.csv                 # Submission format
```

â±ï¸ RUNTIME EXPECTATIONS
- Kaggle GPU: 10-15 minutes âš¡
- Local CPU: 30-60+ minutes â³

ğŸ“Š REQUIREMENTS
```
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=0.24.0
xgboost>=1.5.0
lightgbm>=3.3.0
catboost>=1.0.0
```

ğŸ“ LESSONS FROM OUR JOURNEY
ğŸ’ What We've Learned Competition by Competition

Competition #1 (House Prices): TOP 2.3%
â””â”€ Learning: Feature engineering WINS

Competition #2 (Beats Per Minute): TOP 48.3%
â””â”€ Learning: Ensemble diversity matters

Competition #3+ : Building expertise

Competition #8 (Heart Disease): Healthcare AI
â””â”€ Learning: Domain knowledge + diverse models = POWER

ğŸ”® OUR KAGGLE JOURNEY MAP
âœ… COMPLETED ACHIEVEMENTS
â”œâ”€ House Prices (Get Started): Top 2.3% ğŸ”¥
â”œâ”€ BPM of Songs: Top 48.3%
â”œâ”€ Road Accident Risk: Top 23.5%
â””â”€ Plus 5 more competitions building expertise

ğŸ¯ IN PROGRESS
â”œâ”€ Advanced Ensemble Techniques
â”œâ”€ Feature Engineering Mastery
â”œâ”€ Hyperparameter Optimization
â””â”€ Healthcare AI Excellence

ğŸ† FUTURE TARGETS
â”œâ”€ Competition #9+: Top 10% finishes
â”œâ”€ Featured Competitions: Podium positions
â””â”€ Ultimate Goal: KAGGLE GRANDMASTER STATUS

ğŸ“š LINKS & REFERENCES
- [Kaggle Competition](https://kaggle.com/competitions/playground-series-s6e2)
- [GitHub Repository](https://github.com/mohan13krishna/Predicting-Heart-Disease)
- [Team Phoenix on Kaggle](https://kaggle.com/mohan13krishna)

ğŸ¥ COMPETITION DETAILS
Event: Kaggle Playground Series - Season 6, Episode 2
Dates: February 1 - February 28, 2026
Evaluation: ROC-AUC (Area Under ROC Curve)
Prize: Kaggle Merchandise (Top 3)
License: CC BY 4.0

ğŸ™ ACKNOWLEDGMENTS
- Kaggle for the incredible platform
- Walter Reade & Elizabeth Park for organizing
- Healthcare community for the domain knowledge
- Our team for unwavering dedication
- Coffee for keeping us awake! â˜•

âš¡ THE PHOENIX CONTINUES ITS ASCENT âš¡
"Competition #1: Top 2.3% | Competition #8: Healthcare Prediction | Competition #âˆ: GRANDMASTER!"

ğŸ† TEAM PHOENIX ALGORITHMS ğŸ†
From Good â†’ Great â†’ LEGENDARY
From Learning â†’ Competing â†’ DOMINATING
From Novice â†’ Expert â†’ GRANDMASTER (Coming Soon)

ğŸ“ˆ THE CLIMB NEVER STOPS
We don't just participate. We PURPOSE.
We don't just compete. We CONQUER.
We don't just predict. We IMPACT.

ğŸ–ï¸ 8 Competitions | Multiple Top 10% Finishes | 1 Mission: GRANDMASTER STATUS

Join us on this journey to the top of Kaggle! â­

Competition Link | February 2026 | #TeamPhoenixAlgorithms | ğŸ’–Healthcare EditionğŸ’–

ğŸ’¡ Follow our journey and leave a â­ if this inspires you!
