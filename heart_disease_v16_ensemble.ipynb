{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb2ec68",
   "metadata": {},
   "source": [
    "# ðŸ¥ Heart Disease Prediction - V16 Ensemble\n",
    "\n",
    "## **6-Model Balanced Ensemble with Full Domain Feature Engineering**\n",
    "\n",
    "### Key Features:\n",
    "- **3 algorithms:** LightGBM + CatBoost + XGBoost\n",
    "- **2 seeds each:** [42, 123] for diversity\n",
    "- **13 domain-specific features** from medical knowledge\n",
    "- **Target encoding:** 7 categorical features with smoothing=30\n",
    "- **Meta-learner:** Logistic Regression on OOF predictions\n",
    "\n",
    "### Results:\n",
    "- **Kaggle AUC:** 0.95359\n",
    "- **Rank:** 1038/3981 (26.1%) ðŸŽ¯\n",
    "- **Status:** â­ LATEST - Best Algorithm Diversity!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2aea55",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load datasets (local paths for testing)\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df  = pd.read_csv('test.csv')\n",
    "\n",
    "target_column = 'Heart Disease'\n",
    "X_train = train_df.drop([target_column, 'id'], axis=1)\n",
    "y_train = train_df[target_column].map({'Absence': 0, 'Presence': 1})\n",
    "X_test  = test_df.drop('id', axis=1)\n",
    "test_ids = test_df['id'].values\n",
    "\n",
    "# Fill missing values\n",
    "X_train = X_train.fillna(X_train.median()).reset_index(drop=True)\n",
    "X_test  = X_test.fillna(X_test.median()).reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {X_train.shape} | Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fdc966",
   "metadata": {},
   "source": [
    "## Step 2: Domain Feature Engineering\n",
    "\n",
    "Create 13 medical domain-specific features capturing cardiac patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c13f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Create domain-specific medical features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Chest pain indicators\n",
    "    df['cp_asymptomatic']  = (df['Chest pain type'] == 4).astype(int)\n",
    "    df['cp_angina']        = df['Chest pain type'] * df['Exercise angina']\n",
    "    \n",
    "    # ST segment features (cardiac risk)\n",
    "    df['st_significant']   = (df['ST depression'] > 2.0).astype(int)\n",
    "    df['st_slope_combo']   = df['ST depression'] * df['Slope of ST']\n",
    "    df['angina_st']        = df['Exercise angina'] * df['ST depression']\n",
    "    \n",
    "    # Heart rate analysis\n",
    "    df['max_hr_ratio']     = df['Max HR'] / (220 - df['Age'])  # Estimated max HR ratio\n",
    "    df['hr_reserve']       = (220 - df['Age']) - df['Max HR']  # Heart rate reserve\n",
    "    \n",
    "    # Vascular and blood indicators\n",
    "    df['has_vessels']      = (df['Number of vessels fluro'] > 0).astype(int)\n",
    "    df['vessels_thal']     = df['Number of vessels fluro'] * df['Thallium']\n",
    "    df['high_bp']          = (df['BP'] > 140).astype(int)\n",
    "    df['high_chol']        = (df['Cholesterol'] > 240).astype(int)\n",
    "    \n",
    "    # Thalassemia patterns\n",
    "    df['thal_reversible']  = (df['Thallium'] == 7).astype(int)\n",
    "    df['thal_fixed']       = (df['Thallium'] == 6).astype(int)\n",
    "    \n",
    "    # Age-based risk\n",
    "    df['age_male']         = df['Age'] * df['Sex']\n",
    "    df['fbs_age']          = df['FBS over 120'] * df['Age']\n",
    "    \n",
    "    # Composite risk score\n",
    "    df['risk_score'] = (\n",
    "        df['cp_asymptomatic'] +\n",
    "        df['st_significant'] +\n",
    "        df['has_vessels'] +\n",
    "        df['thal_reversible'] +\n",
    "        df['Exercise angina'] +\n",
    "        (df['ST depression'] > 1.0).astype(int) +\n",
    "        (df['max_hr_ratio'] < 0.7).astype(int)\n",
    "    )\n",
    "    \n",
    "    # Age grouping for categorical patterns\n",
    "    df['age_group'] = pd.cut(\n",
    "        df['Age'], bins=[0,45,55,65,100], labels=[0,1,2,3]\n",
    "    ).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_train = engineer_features(X_train)\n",
    "X_test  = engineer_features(X_test)\n",
    "\n",
    "print(f\"Features after engineering: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea63bd",
   "metadata": {},
   "source": [
    "## Step 3: Target Encoding with Smoothing\n",
    "\n",
    "Apply target encoding inside each CV fold to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cb0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_COLS = ['Chest pain type', 'Thallium', 'Slope of ST',\n",
    "           'Number of vessels fluro', 'EKG results',\n",
    "           'risk_score', 'age_group']\n",
    "\n",
    "def target_encode(X_tr, y_tr, X_val, X_te, cols, smoothing=30):\n",
    "    \"\"\"Target encode features within fold to prevent leakage\"\"\"\n",
    "    gm = y_tr.mean()  # Global mean\n",
    "    X_tr_e, X_val_e, X_te_e = X_tr.copy(), X_val.copy(), X_te.copy()\n",
    "    \n",
    "    for col in cols:\n",
    "        # Smoothed target encoding\n",
    "        stats = y_tr.groupby(X_tr[col]).agg(['sum','count'])\n",
    "        sm = (stats['sum'] + gm * smoothing) / (stats['count'] + smoothing)\n",
    "        \n",
    "        # Map and fill missing values\n",
    "        X_tr_e[f'{col}_te']  = X_tr[col].map(sm).fillna(gm)\n",
    "        X_val_e[f'{col}_te'] = X_val[col].map(sm).fillna(gm)\n",
    "        X_te_e[f'{col}_te']  = X_te[col].map(sm).fillna(gm)\n",
    "    \n",
    "    return X_tr_e, X_val_e, X_te_e\n",
    "\n",
    "print(f\"Will target encode {len(TE_COLS)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e11a35",
   "metadata": {},
   "source": [
    "## Step 4: 5-Fold CV with 6 Models (3 Algorithms Ã— 2 Seeds)\n",
    "\n",
    "Train balanced ensemble with best algorithm diversity:\n",
    "- **1 CV seed:** 42 (fixed)\n",
    "- **2 model seeds:** 42, 123\n",
    "- **3 algorithms:** LightGBM + CatBoost + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "SEEDS   = [42, 123]\n",
    "skf     = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "all_oof   = []\n",
    "all_test  = []\n",
    "all_scores = []\n",
    "\n",
    "print(f\"Training 6 models Ã— {n_folds} folds\")\n",
    "print(f\"Est. runtime: ~5.5 hours\\n\")\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Seed: {seed}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # ======================== LightGBM ========================\n",
    "    oof_lgb  = np.zeros(len(X_train))\n",
    "    test_lgb = np.zeros(len(X_test))\n",
    "    sc_lgb   = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(f\"  LGB fold {fold+1}/5\", end=\"\")\n",
    "\n",
    "        # Target encode within fold\n",
    "        X_tr_e, X_val_e, X_te_e = target_encode(\n",
    "            X_train.iloc[tr_idx], y_train.iloc[tr_idx],\n",
    "            X_train.iloc[val_idx], X_test, TE_COLS)\n",
    "\n",
    "        # LightGBM with optimized params\n",
    "        m = lgb.LGBMClassifier(\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.01,\n",
    "            subsample=0.7,\n",
    "            subsample_freq=1,\n",
    "            colsample_bytree=0.7,\n",
    "            min_child_samples=50,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=5.0,\n",
    "            num_leaves=31,\n",
    "            min_split_gain=0.01,\n",
    "            random_state=seed,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        )\n",
    "        m.fit(X_tr_e, y_train.iloc[tr_idx],\n",
    "              eval_set=[(X_val_e, y_train.iloc[val_idx])],\n",
    "              callbacks=[lgb.early_stopping(200, verbose=False),\n",
    "                         lgb.log_evaluation(-1)])\n",
    "\n",
    "        # Generate predictions\n",
    "        oof_lgb[val_idx] = m.predict_proba(X_val_e)[:, 1]\n",
    "        test_lgb += m.predict_proba(X_te_e)[:, 1] / n_folds\n",
    "        \n",
    "        fold_auc = roc_auc_score(y_train.iloc[val_idx], oof_lgb[val_idx])\n",
    "        sc_lgb.append(fold_auc)\n",
    "        print(f\" â†’ AUC: {fold_auc:.6f}\")\n",
    "\n",
    "    all_oof.append(oof_lgb)\n",
    "    all_test.append(test_lgb)\n",
    "    all_scores.append(sc_lgb)\n",
    "    mean_auc = np.mean(sc_lgb)\n",
    "    std_auc = np.std(sc_lgb)\n",
    "    print(f\"   LGB-s{seed}: {mean_auc:.6f} Â± {std_auc:.6f}\")\n",
    "\n",
    "    # ======================== CatBoost ========================\n",
    "    oof_cat  = np.zeros(len(X_train))\n",
    "    test_cat = np.zeros(len(X_test))\n",
    "    sc_cat   = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(f\"  CAT fold {fold+1}/5\", end=\"\")\n",
    "\n",
    "        # Target encode within fold\n",
    "        X_tr_e, X_val_e, X_te_e = target_encode(\n",
    "            X_train.iloc[tr_idx], y_train.iloc[tr_idx],\n",
    "            X_train.iloc[val_idx], X_test, TE_COLS)\n",
    "\n",
    "        # CatBoost with optimized params\n",
    "        m = CatBoostClassifier(\n",
    "            iterations=10000,\n",
    "            depth=5,\n",
    "            learning_rate=0.01,\n",
    "            l2_leaf_reg=10,\n",
    "            min_data_in_leaf=50,\n",
    "            random_strength=1,\n",
    "            bagging_temperature=0.5,\n",
    "            random_state=seed,\n",
    "            verbose=False,\n",
    "            thread_count=-1,\n",
    "            early_stopping_rounds=200,\n",
    "            eval_metric='AUC'\n",
    "        )\n",
    "        m.fit(X_tr_e, y_train.iloc[tr_idx],\n",
    "              eval_set=(X_val_e, y_train.iloc[val_idx]),\n",
    "              verbose=False)\n",
    "\n",
    "        # Generate predictions\n",
    "        oof_cat[val_idx] = m.predict_proba(X_val_e)[:, 1]\n",
    "        test_cat += m.predict_proba(X_te_e)[:, 1] / n_folds\n",
    "        \n",
    "        fold_auc = roc_auc_score(y_train.iloc[val_idx], oof_cat[val_idx])\n",
    "        sc_cat.append(fold_auc)\n",
    "        print(f\" â†’ AUC: {fold_auc:.6f}\")\n",
    "\n",
    "    all_oof.append(oof_cat)\n",
    "    all_test.append(test_cat)\n",
    "    all_scores.append(sc_cat)\n",
    "    mean_auc = np.mean(sc_cat)\n",
    "    std_auc = np.std(sc_cat)\n",
    "    print(f\"   CAT-s{seed}: {mean_auc:.6f} Â± {std_auc:.6f}\")\n",
    "\n",
    "    # ======================== XGBoost ========================\n",
    "    oof_xgb  = np.zeros(len(X_train))\n",
    "    test_xgb = np.zeros(len(X_test))\n",
    "    sc_xgb   = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(f\"  XGB fold {fold+1}/5\", end=\"\")\n",
    "\n",
    "        # Target encode within fold\n",
    "        X_tr_e, X_val_e, X_te_e = target_encode(\n",
    "            X_train.iloc[tr_idx], y_train.iloc[tr_idx],\n",
    "            X_train.iloc[val_idx], X_test, TE_COLS)\n",
    "\n",
    "        # XGBoost with optimized params\n",
    "        m = xgb.XGBClassifier(\n",
    "            n_estimators=10000,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.01,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.7,\n",
    "            min_child_weight=10,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=5.0,\n",
    "            gamma=0.2,\n",
    "            random_state=seed,\n",
    "            n_jobs=-1,\n",
    "            eval_metric='auc',\n",
    "            early_stopping_rounds=200\n",
    "        )\n",
    "        m.fit(X_tr_e, y_train.iloc[tr_idx],\n",
    "              eval_set=[(X_val_e, y_train.iloc[val_idx])],\n",
    "              verbose=False)\n",
    "\n",
    "        # Generate predictions\n",
    "        oof_xgb[val_idx] = m.predict_proba(X_val_e)[:, 1]\n",
    "        test_xgb += m.predict_proba(X_te_e)[:, 1] / n_folds\n",
    "        \n",
    "        fold_auc = roc_auc_score(y_train.iloc[val_idx], oof_xgb[val_idx])\n",
    "        sc_xgb.append(fold_auc)\n",
    "        print(f\" â†’ AUC: {fold_auc:.6f}\")\n",
    "\n",
    "    all_oof.append(oof_xgb)\n",
    "    all_test.append(test_xgb)\n",
    "    all_scores.append(sc_xgb)\n",
    "    mean_auc = np.mean(sc_xgb)\n",
    "    std_auc = np.std(sc_xgb)\n",
    "    print(f\"   XGB-s{seed}: {mean_auc:.6f} Â± {std_auc:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641cc4e",
   "metadata": {},
   "source": [
    "## Step 5: Ensemble Comparison & Selection\n",
    "\n",
    "Compare 3 ensemble methods and select the best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feed2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"INDIVIDUAL MODEL PERFORMANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "labels = [f'{m}-s{s}' for s in SEEDS for m in ['LGB','CAT','XGB']]\n",
    "for i, label in enumerate(labels):\n",
    "    mean_auc = np.mean(all_scores[i])\n",
    "    std_auc = np.std(all_scores[i])\n",
    "    print(f\"{label:12s}: {mean_auc:.6f} Â± {std_auc:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ENSEMBLE METHODS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ======================== Simple Average ========================\n",
    "simple_oof  = np.mean(all_oof,  axis=0)\n",
    "simple_test = np.mean(all_test, axis=0)\n",
    "simple_auc  = roc_auc_score(y_train, simple_oof)\n",
    "print(f\"Simple Average OOF AUC: {simple_auc:.6f}\")\n",
    "\n",
    "# ======================== Rank Average ========================\n",
    "def rank_avg(preds_list):\n",
    "    \"\"\"Percentile-based rank averaging\"\"\"\n",
    "    r = np.zeros(len(preds_list[0]))\n",
    "    for p in preds_list:\n",
    "        r += pd.Series(p).rank(pct=True).values\n",
    "    return r / len(preds_list)\n",
    "\n",
    "rank_oof  = rank_avg(all_oof)\n",
    "rank_test = rank_avg(all_test)\n",
    "rank_auc  = roc_auc_score(y_train, rank_oof)\n",
    "print(f\"Rank Average OOF AUC:   {rank_auc:.6f}\")\n",
    "\n",
    "# ======================== Meta-model (Logistic Regression) ========================\n",
    "meta = LogisticRegression(C=0.01, max_iter=1000, random_state=42)\n",
    "mtr  = pd.DataFrame({f'm{i}': all_oof[i]  for i in range(len(all_oof))})\n",
    "mte  = pd.DataFrame({f'm{i}': all_test[i] for i in range(len(all_test))})\n",
    "\n",
    "meta.fit(mtr, y_train)\n",
    "meta_oof  = meta.predict_proba(mtr)[:, 1]\n",
    "meta_test = meta.predict_proba(mte)[:, 1]\n",
    "meta_auc  = roc_auc_score(y_train, meta_oof)\n",
    "print(f\"Meta-model OOF AUC:     {meta_auc:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BEST METHOD SELECTED\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ======================== Pick Best ========================\n",
    "scores_dict = {\n",
    "    'simple': (simple_auc, simple_test),\n",
    "    'rank':   (rank_auc,   rank_test),\n",
    "    'meta':   (meta_auc,   meta_test),\n",
    "}\n",
    "best_name = max(scores_dict, key=lambda k: scores_dict[k][0])\n",
    "best_auc, best_test = scores_dict[best_name]\n",
    "print(f\"Best Method: {best_name.upper()}\")\n",
    "print(f\"OOF AUC: {best_auc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0567d7",
   "metadata": {},
   "source": [
    "## Step 6: Generate and Save Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Heart Disease': np.clip(best_test, 0, 1)\n",
    "})\n",
    "\n",
    "# Save to local path\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUBMISSION SAVED\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nFile: submission.csv\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nPrediction range: [{submission['Heart Disease'].min():.6f}, {submission['Heart Disease'].max():.6f}]\")\n",
    "print(f\"\\nâœ… Ready for submission!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
