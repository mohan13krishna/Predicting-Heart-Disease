{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb152b7",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction - V13\n",
    "## Simpler Models with Target Encoding & Reduced Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1587811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d23270",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cda9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "target_column = 'Heart Disease'\n",
    "X_train = train_df.drop([target_column, 'id'], axis=1)\n",
    "y_train = train_df[target_column].map({'Absence': 0, 'Presence': 1})\n",
    "X_test = test_df.drop('id', axis=1)\n",
    "test_ids = test_df['id'].values\n",
    "\n",
    "X_train = X_train.fillna(X_train.median()).reset_index(drop=True)\n",
    "X_test = X_test.fillna(X_test.median()).reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {X_train.shape} | Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc686d",
   "metadata": {},
   "source": [
    "## Target Encoding (Inside CV Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb98bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode(X_tr, y_tr, X_val, X_te, cols, smoothing=20):\n",
    "    \"\"\"Target encode categorical features within fold to avoid leakage\"\"\"\n",
    "    global_mean = y_tr.mean()\n",
    "    X_tr_enc = X_tr.copy()\n",
    "    X_val_enc = X_val.copy()\n",
    "    X_te_enc = X_te.copy()\n",
    "\n",
    "    for col in cols:\n",
    "        stats = y_tr.groupby(X_tr[col]).agg(['sum', 'count'])\n",
    "        smoothed = (stats['sum'] + global_mean * smoothing) / (stats['count'] + smoothing)\n",
    "        X_tr_enc[f'{col}_te'] = X_tr[col].map(smoothed).fillna(global_mean)\n",
    "        X_val_enc[f'{col}_te'] = X_val[col].map(smoothed).fillna(global_mean)\n",
    "        X_te_enc[f'{col}_te'] = X_te[col].map(smoothed).fillna(global_mean)\n",
    "\n",
    "    return X_tr_enc, X_val_enc, X_te_enc\n",
    "\n",
    "# Categorical-like columns to target encode\n",
    "TE_COLS = ['Chest pain type', 'Thallium', 'Slope of ST',\n",
    "           'Number of vessels fluro', 'EKG results']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f6011",
   "metadata": {},
   "source": [
    "## 5-Fold Cross-Validation with 2 Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "SEEDS = [42, 123]\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "all_oof = []\n",
    "all_test = []\n",
    "all_scores = []\n",
    "\n",
    "print(f\"Training 6 models × {n_folds} folds...\\n\")\n",
    "\n",
    "for seed in SEEDS:\n",
    "\n",
    "    # --- LightGBM ---\n",
    "    oof_lgb = np.zeros(len(X_train))\n",
    "    test_lgb = np.zeros(len(X_test))\n",
    "    sc_lgb = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(f\"  LGB s={seed} fold={fold+1}/{n_folds}\")\n",
    "\n",
    "        X_tr_enc, X_val_enc, X_te_enc = target_encode(\n",
    "            X_train.iloc[tr_idx], y_train.iloc[tr_idx],\n",
    "            X_train.iloc[val_idx], X_test, TE_COLS\n",
    "        )\n",
    "\n",
    "        m = lgb.LGBMClassifier(\n",
    "            n_estimators=10000,\n",
    "            max_depth=-1,\n",
    "            learning_rate=0.003,\n",
    "            subsample=0.7,\n",
    "            subsample_freq=1,\n",
    "            colsample_bytree=0.7,\n",
    "            min_child_samples=50,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=5.0,\n",
    "            num_leaves=31,\n",
    "            min_split_gain=0.01,\n",
    "            random_state=seed,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        )\n",
    "        m.fit(X_tr_enc, y_train.iloc[tr_idx],\n",
    "              eval_set=[(X_val_enc, y_train.iloc[val_idx])],\n",
    "              callbacks=[lgb.early_stopping(300, verbose=False),\n",
    "                         lgb.log_evaluation(-1)])\n",
    "\n",
    "        oof_lgb[val_idx] = m.predict_proba(X_val_enc)[:, 1]\n",
    "        test_lgb += m.predict_proba(X_te_enc)[:, 1] / n_folds\n",
    "        sc_lgb.append(roc_auc_score(y_train.iloc[val_idx], oof_lgb[val_idx]))\n",
    "\n",
    "    all_oof.append(oof_lgb)\n",
    "    all_test.append(test_lgb)\n",
    "    all_scores.append(sc_lgb)\n",
    "    print(f\"   LGB s={seed}: {np.mean(sc_lgb):.6f}\\n\")\n",
    "\n",
    "    # --- CatBoost ---\n",
    "    oof_cat = np.zeros(len(X_train))\n",
    "    test_cat = np.zeros(len(X_test))\n",
    "    sc_cat = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(f\"  CAT s={seed} fold={fold+1}/{n_folds}\")\n",
    "\n",
    "        X_tr_enc, X_val_enc, X_te_enc = target_encode(\n",
    "            X_train.iloc[tr_idx], y_train.iloc[tr_idx],\n",
    "            X_train.iloc[val_idx], X_test, TE_COLS\n",
    "        )\n",
    "\n",
    "        m = CatBoostClassifier(\n",
    "            iterations=10000,\n",
    "            depth=5,\n",
    "            learning_rate=0.003,\n",
    "            l2_leaf_reg=10,\n",
    "            min_data_in_leaf=50,\n",
    "            random_strength=1,\n",
    "            bagging_temperature=0.5,\n",
    "            random_state=seed,\n",
    "            verbose=False,\n",
    "            thread_count=-1,\n",
    "            early_stopping_rounds=300,\n",
    "            eval_metric='AUC'\n",
    "        )\n",
    "        m.fit(X_tr_enc, y_train.iloc[tr_idx],\n",
    "              eval_set=(X_val_enc, y_train.iloc[val_idx]),\n",
    "              verbose=False)\n",
    "\n",
    "        oof_cat[val_idx] = m.predict_proba(X_val_enc)[:, 1]\n",
    "        test_cat += m.predict_proba(X_te_enc)[:, 1] / n_folds\n",
    "        sc_cat.append(roc_auc_score(y_train.iloc[val_idx], oof_cat[val_idx]))\n",
    "\n",
    "    all_oof.append(oof_cat)\n",
    "    all_test.append(test_cat)\n",
    "    all_scores.append(sc_cat)\n",
    "    print(f\"  ✅ CAT s={seed}: {np.mean(sc_cat):.6f}\\n\")\n",
    "\n",
    "    # --- XGBoost ---\n",
    "    oof_xgb = np.zeros(len(X_train))\n",
    "    test_xgb = np.zeros(len(X_test))\n",
    "    sc_xgb = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(f\"  XGB s={seed} fold={fold+1}/{n_folds}\")\n",
    "\n",
    "        X_tr_enc, X_val_enc, X_te_enc = target_encode(\n",
    "            X_train.iloc[tr_idx], y_train.iloc[tr_idx],\n",
    "            X_train.iloc[val_idx], X_test, TE_COLS\n",
    "        )\n",
    "\n",
    "        m = xgb.XGBClassifier(\n",
    "            n_estimators=10000,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.003,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.7,\n",
    "            min_child_weight=10,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=5.0,\n",
    "            gamma=0.2,\n",
    "            random_state=seed,\n",
    "            n_jobs=-1,\n",
    "            eval_metric='auc',\n",
    "            early_stopping_rounds=300\n",
    "        )\n",
    "        m.fit(X_tr_enc, y_train.iloc[tr_idx],\n",
    "              eval_set=[(X_val_enc, y_train.iloc[val_idx])],\n",
    "              verbose=False)\n",
    "\n",
    "        oof_xgb[val_idx] = m.predict_proba(X_val_enc)[:, 1]\n",
    "        test_xgb += m.predict_proba(X_te_enc)[:, 1] / n_folds\n",
    "        sc_xgb.append(roc_auc_score(y_train.iloc[val_idx], oof_xgb[val_idx]))\n",
    "\n",
    "    all_oof.append(oof_xgb)\n",
    "    all_test.append(test_xgb)\n",
    "    all_scores.append(sc_xgb)\n",
    "    print(f\"   XGB s={seed}: {np.mean(sc_xgb):.6f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ddd893",
   "metadata": {},
   "source": [
    "## Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8199efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "labels = [f'{m}-s{s}' for s in SEEDS for m in ['LGB','CAT','XGB']]\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"{label:12s}: {np.mean(all_scores[i]):.6f} \"\n",
    "          f\"(+/- {np.std(all_scores[i]):.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df3cc16",
   "metadata": {},
   "source": [
    "## Ensemble Methods Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6027a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple average\n",
    "simple_oof = np.mean(all_oof, axis=0)\n",
    "simple_test = np.mean(all_test, axis=0)\n",
    "simple_auc = roc_auc_score(y_train, simple_oof)\n",
    "print(f\"Simple Average OOF AUC: {simple_auc:.6f}\")\n",
    "\n",
    "# Rank average\n",
    "def rank_avg(preds_list):\n",
    "    r = np.zeros(len(preds_list[0]))\n",
    "    for p in preds_list:\n",
    "        r += pd.Series(p).rank(pct=True).values\n",
    "    return r / len(preds_list)\n",
    "\n",
    "rank_oof = rank_avg(all_oof)\n",
    "rank_test = rank_avg(all_test)\n",
    "rank_auc = roc_auc_score(y_train, rank_oof)\n",
    "print(f\"Rank Average OOF AUC:   {rank_auc:.6f}\")\n",
    "\n",
    "# Meta-model\n",
    "meta = LogisticRegression(C=0.01, max_iter=1000, random_state=42)\n",
    "mtr = pd.DataFrame({f'm{i}': all_oof[i] for i in range(len(all_oof))})\n",
    "mte = pd.DataFrame({f'm{i}': all_test[i] for i in range(len(all_test))})\n",
    "meta.fit(mtr, y_train)\n",
    "meta_oof = meta.predict_proba(mtr)[:, 1]\n",
    "meta_test = meta.predict_proba(mte)[:, 1]\n",
    "meta_auc = roc_auc_score(y_train, meta_oof)\n",
    "print(f\"Meta-model OOF AUC:     {meta_auc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fcb539",
   "metadata": {},
   "source": [
    "## Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best\n",
    "scores_dict = {\n",
    "    'simple': (simple_auc, simple_test),\n",
    "    'rank': (rank_auc, rank_test),\n",
    "    'meta': (meta_auc, meta_test),\n",
    "}\n",
    "best_name = max(scores_dict, key=lambda k: scores_dict[k][0])\n",
    "best_auc, best_test = scores_dict[best_name]\n",
    "print(f\"\\n Best: {best_name} (OOF AUC: {best_auc:.6f})\")\n",
    "\n",
    "# Save\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Heart Disease': np.clip(best_test, 0, 1)\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nSubmission saved!\")\n",
    "print(submission.head(10))\n",
    "print(f\"Range: [{submission['Heart Disease'].min():.6f}, \"\n",
    "      f\"{submission['Heart Disease'].max():.6f}]\")\n",
    "print(\"File: submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
